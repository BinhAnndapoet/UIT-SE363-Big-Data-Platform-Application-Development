# ğŸ“Š BÃO CÃO QUY TRÃŒNH ETL - HARMFUL TIKTOK DETECTION

> **TÃ¡c giáº£**: Auto-generated  
> **NgÃ y cáº­p nháº­t**: 2026-01-02  
> **Dá»± Ã¡n**: UIT-SE363 - PhÃ¡t hiá»‡n ná»™i dung Ä‘á»™c háº¡i trÃªn TikTok

---

## ğŸ“‘ Má»¤C Lá»¤C

1. [Tá»•ng quan kiáº¿n trÃºc](#1-tá»•ng-quan-kiáº¿n-trÃºc)
2. [Phase 1: Extract - Crawl dá»¯ liá»‡u](#2-phase-1-extract---crawl-dá»¯-liá»‡u)
3. [Phase 2: Transform - Tiá»n xá»­ lÃ½ vÃ  gÃ¡n nhÃ£n](#3-phase-2-transform---tiá»n-xá»­-lÃ½-vÃ -gÃ¡n-nhÃ£n)
4. [Phase 3: Load - Chia splits vÃ  náº¡p vÃ o model](#4-phase-3-load---chia-splits-vÃ -náº¡p-vÃ o-model)
5. [Cáº¥u trÃºc thÆ° má»¥c vÃ  file data](#5-cáº¥u-trÃºc-thÆ°-má»¥c-vÃ -file-data)
6. [CÃ¡c váº¥n Ä‘á» Ä‘Ã£ gáº·p vÃ  giáº£i phÃ¡p](#6-cÃ¡c-váº¥n-Ä‘á»-Ä‘Ã£-gáº·p-vÃ -giáº£i-phÃ¡p)
7. [Káº¿t luáº­n vÃ  khuyáº¿n nghá»‹](#7-káº¿t-luáº­n-vÃ -khuyáº¿n-nghá»‹)

---

## 1. Tá»”NG QUAN KIáº¾N TRÃšC

### 1.1 Pipeline tá»•ng thá»ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ETL PIPELINE OVERVIEW                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  CRAWL     â”‚â”€â”€â”€â–¶â”‚  PREPROCESS  â”‚â”€â”€â”€â–¶â”‚   LABELING   â”‚â”€â”€â”€â–¶â”‚  COMBINE   â”‚   â”‚
â”‚  â”‚  TikTok    â”‚    â”‚  & Clean     â”‚    â”‚   (LLM AI)   â”‚    â”‚  Files     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â”‚                  â”‚                   â”‚                   â”‚          â”‚
â”‚        â”‚    FOLDER: preprocess/              â”‚                   â”‚          â”‚
â”‚        â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚        â”‚                                      â”‚                              â”‚
â”‚        â–¼                                      â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ data/      â”‚                        â”‚ processed_   â”‚                     â”‚
â”‚  â”‚ data_1/    â”‚                        â”‚ data/text/   â”‚                     â”‚
â”‚  â”‚ data_viet/ â”‚                        â”‚ COMBINED.csv â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                               â”‚                              â”‚
â”‚                                               â–¼                              â”‚
â”‚                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                             â”‚    SPLIT DATA (80/10/10)    â”‚                 â”‚
â”‚                             â”‚    FOLDER: train_eval_moduleâ”‚                 â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                    â”‚         â”‚         â”‚                    â”‚
â”‚                                    â–¼         â–¼         â–¼                    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                              â”‚ TRAIN  â”‚ â”‚  VAL   â”‚ â”‚  TEST  â”‚               â”‚
â”‚                              â”‚ 80%    â”‚ â”‚  10%   â”‚ â”‚  10%   â”‚               â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                               â”‚                              â”‚
â”‚                                               â–¼                              â”‚
â”‚                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                             â”‚    CLEAN TEXT (runtime)     â”‚                 â”‚
â”‚                             â”‚    + TOKENIZE â†’ MODEL       â”‚                 â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Hai folder chÃ­nh trong pipeline

| Folder | Má»¥c Ä‘Ã­ch | Input | Output |
|--------|----------|-------|--------|
| `preprocess/` | ETL offline (cháº¡y 1 láº§n) | Videos + Comments tá»« crawl | `TRAINING_DATA_FINAL_*.csv` |
| `train_eval_module/` | Training & Evaluation | CSV Ä‘Ã£ gÃ¡n nhÃ£n | Model checkpoints |

---

## 2. PHASE 1: EXTRACT - CRAWL Dá»® LIá»†U

### 2.1 Quy trÃ¬nh crawl

**Folder nguá»“n**: `UIT-SE363-Big-Data-Platform-Application-Development/`

| File | Chá»©c nÄƒng |
|------|-----------|
| `find_tiktok_links.py` | TÃ¬m link TikTok theo hashtag |
| `create_sub_samples_tiktok_links.py` | Táº¡o subset links Ä‘á»ƒ crawl |
| `ScrapingVideoTiktok.py` | Download video + comments |
| `crawl_tiktok_links_update_v1.py` | Cáº­p nháº­t crawl batch |
| `crawl_tiktok_links_update_viet.py` | Crawl riÃªng data tiáº¿ng Viá»‡t |

### 2.2 Cáº¥u trÃºc data sau crawl

```
UIT-SE363.../
â”œâ”€â”€ data/                          # Batch crawl 1
â”‚   â”œâ”€â”€ videos/
â”‚   â”‚   â”œâ”€â”€ harmful/               # 435 videos
â”‚   â”‚   â”‚   â”œâ”€â”€ video_001/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 7522809443281669383.mp4
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 7522809443281669383_comments.xlsx
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ not_harmful/           # 524 videos
â”‚   â””â”€â”€ crawl/
â”‚       â””â”€â”€ tiktok_links.csv       # Links Ä‘Ã£ crawl
â”‚
â”œâ”€â”€ data_1/                        # Batch crawl 2
â”‚   â”œâ”€â”€ videos/
â”‚   â”‚   â”œâ”€â”€ harmful/               # 540 videos
â”‚   â”‚   â””â”€â”€ not_harmful/           # 298 videos
â”‚   â””â”€â”€ crawl/
â”‚
â””â”€â”€ data_viet/                     # Batch crawl 3 (tiáº¿ng Viá»‡t)
    â”œâ”€â”€ videos/
    â”‚   â”œâ”€â”€ harmful/               # 540 videos
    â”‚   â””â”€â”€ not_harmful/           # 278 videos
    â””â”€â”€ crawl/
```

### 2.3 Thá»‘ng kÃª dá»¯ liá»‡u crawl

> **LÆ°u Ã½**: CÃ¡c con sá»‘ thá»‘ng kÃª (Harmful/Not Harmful/Total) phá»¥ thuá»™c vÃ o thá»i Ä‘iá»ƒm crawl vÃ  sá»‘ file video hiá»‡n cÃ³.
> Khi chá»‘t sá»‘ liá»‡u cho bÃ¡o cÃ¡o cuá»‘i, nÃªn láº¥y theo output thá»±c táº¿ cá»§a script split:
> `train_eval_module/scripts/split_data.py` (pháº§n â€œğŸš€ Äang quÃ©t dá»¯ liá»‡u videoâ€¦â€).

| Source Folder | Harmful | Not Harmful | Total Videos |
|---------------|---------|-------------|--------------|
| `data/` | 435 | 524 | 959 |
| `data_1/` | 540 | 298 | 838 |
| `data_viet/` | 540 | 278 | 818 |
| **Tá»”NG (cÃ³ trÃ¹ng)** | 1,515 | 1,100 | **2,615** |
| **UNIQUE (sau dedupe)** | - | - | **1,950** |

---

## 3. PHASE 2: TRANSFORM - TIá»€N Xá»¬ LÃ VÃ€ GÃN NHÃƒN

### 3.1 Pipeline xá»­ lÃ½ (folder `preprocess/`)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PREPROCESS PIPELINE (STEP BY STEP)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STEP 1: MERGE COMMENTS                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  File: merge_comments_new.py                                             â”‚
â”‚  Input:  data/videos/*_comments.xlsx                                     â”‚
â”‚  Output: output/data.csv                                                 â”‚
â”‚                                                                          â”‚
â”‚  Chá»©c nÄƒng:                                                              â”‚
â”‚  - QuÃ©t táº¥t cáº£ file *_comments.xlsx trong folder videos/                 â”‚
â”‚  - Gá»™p táº¥t cáº£ comments vÃ o 1 CSV vá»›i columns: video_id, text, path       â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ data.csv      â”‚      â”‚ data_1.csv    â”‚      â”‚ data_viet.csv â”‚        â”‚
â”‚  â”‚ (raw comments)â”‚      â”‚ (raw comments)â”‚      â”‚ (raw comments)â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STEP 2: PREPROCESS & AGGREGATE                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  File: preprocess_new.py                                                 â”‚
â”‚  Input:  output/data.csv                                                 â”‚
â”‚  Output: output/preprocessed_data.csv                                    â”‚
â”‚                                                                          â”‚
â”‚  Chá»©c nÄƒng:                                                              â”‚
â”‚  - Clean text: lowercase, remove URLs, fix teencode                      â”‚
â”‚  - AGGREGATE: Gá»™p Táº¤T Cáº¢ comments cá»§a cÃ¹ng video_id thÃ nh 1 row          â”‚
â”‚  - Giá»›i háº¡n max 50 comments/video (random sample)                        â”‚
â”‚  - Ná»‘i cÃ¡c comments báº±ng " . " separator                                 â”‚
â”‚                                                                          â”‚
â”‚  âš ï¸ QUAN TRá»ŒNG: ÄÃ¢y lÃ  nÆ¡i comments Ä‘Æ°á»£c gá»™p theo video_id               â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STEP 3: LABELING (AI/LLM)                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  File: label_comments_new.py                                             â”‚
â”‚  Input:  output/preprocessed_data.csv                                    â”‚
â”‚  Output: output/TRAINING_TEXT_DATA_NEW_data.csv                          â”‚
â”‚                                                                          â”‚
â”‚  Chá»©c nÄƒng:                                                              â”‚
â”‚  - Sá»­ dá»¥ng LLM local Ä‘á»ƒ gÃ¡n nhÃ£n (pipeline.sh Ä‘ang gá»i label_comments_new.py)â”‚
â”‚    - Model máº·c Ä‘á»‹nh hiá»‡n set trong preprocess/config.py: Qwen/Qwen2.5-7B-Instruct
â”‚  - NhÃ£n: 0 (Safe/Not Harmful) hoáº·c 1 (Harmful)                          â”‚
â”‚  - Confidence score kÃ¨m theo                                             â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STEP 4: CLEAN & VERIFY                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  File: clean_final_dataset.py + check_label_results.py                   â”‚
â”‚  Input:  output/TRAINING_TEXT_DATA_NEW_data.csv                          â”‚
â”‚  Output: output/TRAINING_DATA_FINAL_data.csv                             â”‚
â”‚                                                                          â”‚
â”‚  Chá»©c nÄƒng:                                                              â”‚
â”‚  - (Tuá»³ config) Loáº¡i bá» cÃ¡c row cÃ³ confidence tháº¥p (ngÆ°á»¡ng cÃ³ thá»ƒ thay Ä‘á»•i)â”‚
â”‚  - Kiá»ƒm tra vÃ  sá»­a label khÃ´ng nháº¥t quÃ¡n                                 â”‚
â”‚  - Lá»c text quÃ¡ ngáº¯n hoáº·c rá»—ng                                          â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STEP 5: COMBINE FILES                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  File: combine_file.py                                                   â”‚
â”‚  Input:  TRAINING_DATA_FINAL_data.csv                                    â”‚
â”‚          TRAINING_DATA_FINAL_data_1.csv                                  â”‚
â”‚          TRAINING_DATA_FINAL_data_viet.csv                               â”‚
â”‚  Output: processed_data/text/TRAINING_TEXT_DATA_FINAL_COMBINED.csv       â”‚
â”‚                                                                          â”‚
â”‚  Chá»©c nÄƒng:                                                              â”‚
â”‚  - Gá»™p 3 file tá»« 3 batch crawl thÃ nh 1 file duy nháº¥t                    â”‚
â”‚  - Shuffle random                                                        â”‚
â”‚  - (Theo preprocess_pipeline.sh) bÆ°á»›c nÃ y Ä‘Æ°á»£c gá»i á»Ÿ **BÆ¯á»šC 6: Gá»˜P Dá»® LIá»†U**
â”‚  - Output path lÃ  Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i khi cháº¡y trong folder preprocess/
â”‚    (máº·c Ä‘á»‹nh: processed_data/text/TRAINING_TEXT_DATA_FINAL_COMBINED.csv)
â”‚  - Sau Ä‘Ã³ cáº§n Ä‘áº£m báº£o file COMBINED náº±m trong repo chÃ­nh Ä‘á»ƒ training Ä‘á»c Ä‘Æ°á»£c:
â”‚    UIT-SE363-Big-Data-Platform-Application-Development/processed_data/text/
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Chi tiáº¿t cÃ¡c file xá»­ lÃ½

| File | Input | Output | Chá»©c nÄƒng chÃ­nh |
|------|-------|--------|-----------------|
| `merge_comments_new.py` | `*_comments.xlsx` | `data.csv` | Gá»™p comments tá»« Excel |
| `preprocess_new.py` | `data.csv` | `preprocessed_data.csv` | Clean + Aggregate theo video_id |
| `label_comments_new.py` | `preprocessed_data.csv` | `TRAINING_TEXT_DATA_NEW_*.csv` | GÃ¡n nhÃ£n báº±ng LLM |
| `clean_final_dataset.py` | `TRAINING_TEXT_DATA_NEW_*.csv` | `TRAINING_DATA_FINAL_*.csv` | Lá»c confidence tháº¥p |
| `combine_file.py` | Multiple CSVs | `COMBINED.csv` | Gá»™p nhiá»u file |

### 3.3 Cáº¥u trÃºc dá»¯ liá»‡u sau má»—i step

**Step 1 (Merge) - `data.csv`:**
```csv
video_id,text,path
7522809443281669383,"dream body",not_harmful/video_844/7522809443281669383.mp4
7522809443281669383,"cleaning my fyp",not_harmful/video_844/7522809443281669383.mp4
7516567349839858952,"mÃ¬nh láº¥y láº¡i Ä‘Æ°á»£c rá»“i",harmful/video_292/7516567349839858952.mp4
```
â†’ Má»—i comment lÃ  1 row riÃªng

**Step 2 (Preprocess) - `preprocessed_data.csv`:**
```csv
video_id,path,text_clean,filename
7522809443281669383,not_harmful/video_844/...,dream body . cleaning my fyp . ...,7522809443281669383.mp4
```
â†’ Gá»™p thÃ nh 1 row/video vá»›i separator " . "

**Step 3 (Label) - `TRAINING_TEXT_DATA_NEW_*.csv`:**
```csv
video_id,path,filename,text,label,confidence
7522809443281669383,not_harmful/...,7522809443281669383.mp4,"dream body . ...",0,0.95
```
â†’ ThÃªm label vÃ  confidence tá»« LLM

---

## 4. PHASE 3: LOAD - CHIA SPLITS VÃ€ Náº P VÃ€O MODEL

### 4.1 Pipeline trong `train_eval_module/`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAIN_EVAL_MODULE PIPELINE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  INPUT: processed_data/text/TRAINING_TEXT_DATA_FINAL_COMBINED.csv        â”‚
â”‚                                                                          â”‚
â”‚  STEP 1: SPLIT DATA                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  File: scripts/split_data.py                                             â”‚
â”‚  Config: configs/paths.py (DATA_SOURCES = ["data", "data_1", "data_viet"])â”‚
â”‚                                                                          â”‚
â”‚  Chá»©c nÄƒng:                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. Táº¡o MASTER INDEX tá»« video files:                              â”‚    â”‚
â”‚  â”‚    - QuÃ©t data/, data_1/, data_viet/ tÃ¬m táº¥t cáº£ .mp4             â”‚    â”‚
â”‚  â”‚    - De-duplicate theo video_id                                   â”‚    â”‚
â”‚  â”‚    - Stratified split 80/10/10                                    â”‚    â”‚
â”‚  â”‚    â†’ Output: data_splits/train_split.json, val_split.json,        â”‚    â”‚
â”‚  â”‚              test_split.json                                      â”‚    â”‚
â”‚  â”‚                                                                   â”‚    â”‚
â”‚  â”‚ 2. Táº¡o TEXT SPLITS align vá»›i MASTER:                             â”‚    â”‚
â”‚  â”‚    - Äá»c TRAINING_TEXT_DATA_FINAL_COMBINED.csv                   â”‚    â”‚
â”‚  â”‚    - Map video_id vá»›i MASTER splits                               â”‚    â”‚
â”‚  â”‚    - Re-aggregate text theo video_id (1 row/video)               â”‚    â”‚
â”‚  â”‚    â†’ Output: processed_data/text/train_split.csv, eval_split.csv,â”‚    â”‚
â”‚  â”‚              test_split.csv                                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STEP 2: RUNTIME CLEAN TEXT (khi load vÃ o model)                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”‚
â”‚  File: text/src/dataset.py â†’ clean_text()                                â”‚
â”‚                                                                          â”‚
â”‚  Chá»©c nÄƒng (Ã¡p dá»¥ng lÃºc tokenize):                                       â”‚
â”‚  - Unicode normalize (NFKC)                                              â”‚
â”‚  - Replace URLs â†’ [url], @mentions â†’ [user]                              â”‚
â”‚  - Reduce character repetition (quÃ¡aaa â†’ quÃ¡)                            â”‚
â”‚  - â­ Split by " . " hoáº·c newlines â†’ De-duplicate â†’ Join vá»›i " [cmt] "   â”‚
â”‚  - Hard cap 20,000 chars                                                 â”‚
â”‚                                                                          â”‚
â”‚  âš ï¸ QUAN TRá»ŒNG: Separator " . " tá»« preprocessing Ä‘Æ°á»£c convert sang       â”‚
â”‚     "[cmt]" token Ä‘á»ƒ model cÃ³ thá»ƒ há»c ranh giá»›i comment                  â”‚
â”‚                                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  STEP 3: TRAINING                                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  File: text/train.py                                                     â”‚
â”‚  Config: text/text_configs.py                                            â”‚
â”‚                                                                          â”‚
â”‚  Models available:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ idx â”‚ Model Name                        â”‚ Best for             â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚  0  â”‚ uitnlp/CafeBERT                   â”‚ Text 90%+ Tiáº¿ng Viá»‡t â”‚     â”‚
â”‚  â”‚  1  â”‚ xlm-roberta-base                  â”‚ Multilingual mixed   â”‚     â”‚
â”‚  â”‚  2  â”‚ distilbert-base-multilingual-casedâ”‚ Fast, lightweight    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 File cáº¥u hÃ¬nh quan trá»ng

**`configs/paths.py`:**
```python
# DATA SOURCES - Pháº£i bao gá»“m Táº¤T Cáº¢ folder chá»©a video
DATA_SOURCES = ["data", "data_1", "data_viet"]  # âš ï¸ Thiáº¿u folder sáº½ máº¥t data!

# Input cho text splits
TEXT_LABEL_FILE = ".../processed_data/text/TRAINING_TEXT_DATA_FINAL_COMBINED.csv"

# Output splits
TEXT_TRAIN_CSV = ".../processed_data/text/train_split.csv"
TEXT_VAL_CSV   = ".../processed_data/text/eval_split.csv"
TEXT_TEST_CSV  = ".../processed_data/text/test_split.csv"
```

### 4.3 Thá»‘ng kÃª splits cuá»‘i cÃ¹ng

| Split | Videos | Label 0 (Not Harmful) | Label 1 (Harmful) |
|-------|--------|----------------------|-------------------|
| Train | 1,456 | 616 (42.3%) | 840 (57.7%) |
| Val | 185 | 79 (42.7%) | 106 (57.3%) |
| Test | 179 | 79 (44.1%) | 100 (55.9%) |
| **Total** | **1,820** | - | - |

---

## 5. Cáº¤U TRÃšC THÆ¯ Má»¤C VÃ€ FILE DATA

### 5.1 Tá»•ng quan

```
/home/guest/Projects/SE363/
â”‚
â”œâ”€â”€ preprocess/                              # ETL offline
â”‚   â”œâ”€â”€ config.py                            # Cáº¥u hÃ¬nh paths
â”‚   â”œâ”€â”€ preprocess_pipeline.sh               # Script cháº¡y pipeline
â”‚   â”œâ”€â”€ merge_comments_new.py                # Step 1: Merge
â”‚   â”œâ”€â”€ preprocess_new.py                    # Step 2: Clean + Aggregate
â”‚   â”œâ”€â”€ label_comments_new.py                # Step 3: AI Labeling
â”‚   â”œâ”€â”€ clean_final_dataset.py               # Step 4: Filter
â”‚   â”œâ”€â”€ combine_file.py                      # Step 5: Combine
â”‚   â”‚
â”‚   â””â”€â”€ output/                              # Output cá»§a má»—i step
â”‚       â”œâ”€â”€ data.csv                         # Step 1 output
â”‚       â”œâ”€â”€ data_1.csv
â”‚       â”œâ”€â”€ data_viet.csv
â”‚       â”œâ”€â”€ preprocessed_data.csv            # Step 2 output
â”‚       â”œâ”€â”€ preprocessed_data_1.csv
â”‚       â”œâ”€â”€ preprocessed_data_viet.csv
â”‚       â”œâ”€â”€ TRAINING_TEXT_DATA_NEW_data.csv  # Step 3 output
â”‚       â”œâ”€â”€ TRAINING_TEXT_DATA_NEW_data_1.csv
â”‚       â”œâ”€â”€ TRAINING_TEXT_DATA_NEW_data_viet.csv
â”‚       â”œâ”€â”€ TRAINING_DATA_FINAL_data.csv     # Step 4 output
â”‚       â”œâ”€â”€ TRAINING_DATA_FINAL_data_1.csv
â”‚       â””â”€â”€ TRAINING_DATA_FINAL_data_viet.csv
â”‚
â””â”€â”€ UIT-SE363-Big-Data-Platform-Application-Development/
    â”‚
    â”œâ”€â”€ data/videos/                         # Video files batch 1
    â”œâ”€â”€ data_1/videos/                       # Video files batch 2
    â”œâ”€â”€ data_viet/videos/                    # Video files batch 3
    â”‚
    â”œâ”€â”€ processed_data/text/                 # Data Ä‘Ã£ xá»­ lÃ½ cho training
    â”‚   â”œâ”€â”€ TRAINING_TEXT_DATA_FINAL_COMBINED.csv  # â­ Input cho split
    â”‚   â”œâ”€â”€ train_split.csv                  # Output train
    â”‚   â”œâ”€â”€ eval_split.csv                   # Output validation
    â”‚   â””â”€â”€ test_split.csv                   # Output test
    â”‚
    â””â”€â”€ train_eval_module/
        â”œâ”€â”€ configs/
        â”‚   â””â”€â”€ paths.py                     # âš ï¸ DATA_SOURCES config
        â”‚
        â”œâ”€â”€ scripts/
        â”‚   â”œâ”€â”€ split_data.py                # Chia train/val/test
        â”‚   â””â”€â”€ analyze_text_splits.py       # Tool phÃ¢n tÃ­ch data
        â”‚
        â”œâ”€â”€ data_splits/                     # MASTER index (video-based)
        â”‚   â”œâ”€â”€ train_split.json
        â”‚   â”œâ”€â”€ val_split.json
        â”‚   â””â”€â”€ test_split.json
        â”‚
        â””â”€â”€ text/
            â”œâ”€â”€ text_configs.py              # Model configs
            â”œâ”€â”€ train.py                     # Training script
            â”œâ”€â”€ test.py                      # Test script
            â””â”€â”€ src/
                â””â”€â”€ dataset.py               # clean_text(), load_text_data()
```

### 5.2 Flow dá»¯ liá»‡u chi tiáº¿t

```
VIDEO FILES                          TEXT/COMMENTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
data/videos/*.mp4         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  *_comments.xlsx
data_1/videos/*.mp4       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  *_comments.xlsx  
data_viet/videos/*.mp4    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  *_comments.xlsx
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚ merge_comments_new.py â”‚
        â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                           preprocess/output/
        â”‚                        â”œâ”€â”€ data.csv
        â”‚                        â”œâ”€â”€ data_1.csv
        â”‚                        â””â”€â”€ data_viet.csv
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚  preprocess_new.py    â”‚
        â”‚                        â”‚  (Aggregate by vid_id)â”‚
        â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                        â”œâ”€â”€ preprocessed_data.csv
        â”‚                        â”œâ”€â”€ preprocessed_data_1.csv
        â”‚                        â””â”€â”€ preprocessed_data_viet.csv
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚ label_comments_new.py â”‚
        â”‚                        â”‚    (Qwen2.5 LLM)      â”‚
        â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                        â”œâ”€â”€ TRAINING_DATA_FINAL_data.csv
        â”‚                        â”œâ”€â”€ TRAINING_DATA_FINAL_data_1.csv
        â”‚                        â””â”€â”€ TRAINING_DATA_FINAL_data_viet.csv
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚    combine_file.py    â”‚
        â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                    â”‚
        â”‚                                    â–¼
        â”‚                        TRAINING_TEXT_DATA_FINAL_COMBINED.csv
        â”‚                                    â”‚
        â”‚                                    â”‚
        â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      split_data.py                             â”‚
â”‚  1. Scan video files â†’ MASTER INDEX (dedupe by video_id)       â”‚
â”‚  2. Stratified split 80/10/10                                  â”‚
â”‚  3. Align TEXT CSV to MASTER â†’ TEXT SPLITS                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                    â”‚
        â–¼                                    â–¼
data_splits/*.json              processed_data/text/*_split.csv
(Video/Audio index)             (Text splits for training)
```

---

## 6. CÃC Váº¤N Äá»€ ÄÃƒ Gáº¶P VÃ€ GIáº¢I PHÃP

### 6.1 Issue #1: DATA_SOURCES thiáº¿u `data_viet`

**Váº¥n Ä‘á»:**
```python
# configs/paths.py (CÅ¨)
DATA_SOURCES = ["data", "data_1"]  # Thiáº¿u data_viet!
```

**Háº­u quáº£:**
- MASTER INDEX chá»‰ cÃ³ 1,133 videos (tá»« data/ vÃ  data_1/)
- TEXT CSV cÃ³ 1,820 videos (bao gá»“m cáº£ data_viet/)
- **768 videos bá»‹ DROP** vÃ¬ khÃ´ng match vá»›i MASTER

**Giáº£i phÃ¡p:**
```python
# configs/paths.py (Má»šI)
DATA_SOURCES = ["data", "data_1", "data_viet"]
```

**Káº¿t quáº£ sau fix:**
| Metric | TrÆ°á»›c | Sau |
|--------|-------|-----|
| MASTER videos | 1,133 | 1,950 |
| Text videos in splits | 1,052 | 1,820 |
| Dropped videos | 768 | 0 |

---

### 6.2 Issue #2: Separator " . " khÃ´ng Ä‘Æ°á»£c xá»­ lÃ½ Ä‘Ãºng

**Váº¥n Ä‘á»:**
- `preprocess_new.py` gá»™p comments báº±ng `" . "` separator
- `dataset.py::clean_text()` chá»‰ split theo `[\r\n]+` (newlines)
- Káº¿t quáº£: Comments khÃ´ng Ä‘Æ°á»£c tÃ¡ch ra, `[cmt]` token khÃ´ng Ä‘Æ°á»£c thÃªm

**Code cÅ© (SAI):**
```python
# dataset.py
lines = re.split(r"[\r\n]+", text)  # Chá»‰ split theo newlines
```

**Code má»›i (ÄÃšNG):**
```python
# dataset.py  
lines = re.split(r"[\r\n]+|\s+\.\s+", text)  # Split theo newlines HOáº¶C " . "
```

**Káº¿t quáº£:**
| Metric | TrÆ°á»›c fix | Sau fix |
|--------|-----------|---------|
| Mean comments/video | 1.0 | ~15-20 |
| `[cmt]` tokens added | âŒ No | âœ… Yes |

---

### 6.3 Issue #3: DistilBERT over-regularized config

**Váº¥n Ä‘á»:**
- Ban Ä‘áº§u config DistilBERT quÃ¡ regularized (dropout cao, weight_decay cao)
- Model bá»‹ bias, predict 100% Harmful

**Config cÅ© (SAI):**
```python
TEXT_MODEL_OVERRIDES = {
    2: {
        "epochs": 15,
        "hidden_dropout_prob": 0.3,  # QuÃ¡ cao!
        "weight_decay": 0.15,        # QuÃ¡ cao!
    }
}
```

**Config má»›i (ÄÃšNG):**
```python
TEXT_MODEL_OVERRIDES = {
    2: {
        "epochs": 12,
        "warmup_ratio": 0.15,
        "lr": 3e-5,
        # Giá»¯ dropout vÃ  weight_decay máº·c Ä‘á»‹nh (0.1, 0.05)
    }
}
```

---

### 6.4 Issue #4: Video ID precision loss

**Váº¥n Ä‘á»:**
- TikTok video_id cÃ³ 18-19 digits
- Pandas Ä‘á»c CSV máº·c Ä‘á»‹nh lÃ  float64 â†’ precision loss
- `7522809443281669383` cÃ³ thá»ƒ thÃ nh `7.52280944e+18`

**Giáº£i phÃ¡p:**
```python
df = pd.read_csv(TEXT_LABEL_FILE, dtype=str, low_memory=False)
# Äá»c táº¥t cáº£ columns as string Ä‘á»ƒ giá»¯ precision
```

---

### 6.5 Tá»•ng há»£p cÃ¡c váº¥n Ä‘á»

| # | Issue | Root Cause | Fix | Impact |
|---|-------|------------|-----|--------|
| 1 | 768 videos dropped | `DATA_SOURCES` thiáº¿u `data_viet` | ThÃªm vÃ o config | +73% data |
| 2 | `[cmt]` khÃ´ng hoáº¡t Ä‘á»™ng | `clean_text()` khÃ´ng split " . " | Fix regex pattern | Better tokenization |
| 3 | Model bias | Over-regularization | Reset to defaults | +20% accuracy |
| 4 | video_id mismatch | Float precision loss | Read as string | Proper alignment |

---

## 7. Káº¾T LUáº¬N VÃ€ KHUYáº¾N NGHá»Š

### 7.1 Káº¿t quáº£ training vá»›i data Ä‘áº§y Ä‘á»§

| Model | Accuracy | F1-Score | Notes |
|-------|----------|----------|-------|
| **CafeBERT** | **82.12%** | **81.99%** | Best cho Vietnamese-heavy data |
| **XLM-RoBERTa** | **82.12%** | **81.84%** | Good multilingual support |
| DistilBERT | 74.30% | 73.71% | Lightweight, fast inference |

### 7.2 CÃ³ nÃªn crawl thÃªm dá»¯ liá»‡u?

**âœ… CÃ“ - Crawl thÃªm sáº½ TÄ‚NG káº¿t quáº£ vÃ¬:**

1. **Dataset hiá»‡n táº¡i cÃ²n nhá»**: 1,820 videos lÃ  khÃ¡ Ã­t cho deep learning
2. **DistilBERT cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ khi cÃ³ thÃªm data**: +12% khi thÃªm `data_viet`
3. **Class imbalance**: Harmful (57.7%) vs Not Harmful (42.3%) - cáº§n balance hÆ¡n

**Khuyáº¿n nghá»‹ crawl:**
- ThÃªm ~1,000-2,000 videos ná»¯a
- Æ¯u tiÃªn class Not Harmful Ä‘á»ƒ balance
- Äa dáº¡ng hashtags vÃ  categories

### 7.3 CÃ¡ch gá»™p comments theo video_id cÃ³ Ä‘Ãºng khÃ´ng?

**âœ… ÄÃšNG - ÄÃ¢y lÃ  hÆ°á»›ng xá»­ lÃ½ Tá»T vÃ¬:**

1. **TrÃ¡nh data leakage**: Náº¿u khÃ´ng gá»™p, cÃ¹ng 1 video cÃ³ thá»ƒ xuáº¥t hiá»‡n á»Ÿ cáº£ train vÃ  test
2. **Context Ä‘áº§y Ä‘á»§ hÆ¡n**: Model nhÃ¬n tháº¥y nhiá»u comments cÃ¹ng lÃºc, hiá»ƒu "khÃ´ng khÃ­ chung"
3. **PhÃ¹ há»£p multimodal**: Text vÃ  Video Ä‘Æ°á»£c align theo video_id
4. **Giáº£m noise**: De-duplicate comments trÃ¹ng láº·p

**Cáº£i tiáº¿n cÃ³ thá»ƒ:**
- Sá»­ dá»¥ng sliding window cho texts > 512 tokens (hiá»‡n cÃ³ ~57% texts dÃ i hÆ¡n)
- Thá»­ nghiá»‡m `max_comments = 30` thay vÃ¬ 50 Ä‘á»ƒ giáº£m truncation

### 7.4 Pipeline tá»‘i Æ°u Ä‘á» xuáº¥t

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RECOMMENDED PIPELINE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1. CRAWL: Má»Ÿ rá»™ng dataset Ä‘áº¿n 3,000-5,000 videos                       â”‚
â”‚     - Balance harmful/not_harmful ratio (50/50)                          â”‚
â”‚     - Äa dáº¡ng nguá»“n: hashtags, trending, user reports                   â”‚
â”‚                                                                          â”‚
â”‚  2. PREPROCESS:                                                          â”‚
â”‚     - Giá»¯ nguyÃªn pipeline hiá»‡n táº¡i (Ä‘Ã£ hoáº¡t Ä‘á»™ng tá»‘t)                   â”‚
â”‚     - CÃ¢n nháº¯c giáº£m max_comments tá»« 50 â†’ 30                             â”‚
â”‚                                                                          â”‚
â”‚  3. SPLIT:                                                               â”‚
â”‚     - âš ï¸ LUÃ”N kiá»ƒm tra DATA_SOURCES cÃ³ Ä‘áº§y Ä‘á»§ folders                   â”‚
â”‚     - Cháº¡y analyze_text_splits.py sau má»—i láº§n split                     â”‚
â”‚                                                                          â”‚
â”‚  4. TRAIN:                                                               â”‚
â”‚     - CafeBERT cho data chá»§ yáº¿u tiáº¿ng Viá»‡t                              â”‚
â”‚     - XLM-RoBERTa cho data Ä‘a ngÃ´n ngá»¯                                  â”‚
â”‚     - Thá»­ nghiá»‡m sliding window cho long texts                          â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ PHá»¤ Lá»¤C

### A. Cháº¡y toÃ n bá»™ pipeline

```bash
# 1. Cháº¡y preprocess cho tá»«ng batch
cd /home/guest/Projects/SE363/preprocess
./preprocess_pipeline.sh  # Chá»n mode 1, folder data/data_1/data_viet

# 2. Combine files
python combine_file.py \
  --inputs TRAINING_DATA_FINAL_data.csv TRAINING_DATA_FINAL_data_1.csv TRAINING_DATA_FINAL_data_viet.csv \
    --output processed_data/text/TRAINING_TEXT_DATA_FINAL_COMBINED.csv

# (LÆ°u Ã½) split_data.py trong repo chÃ­nh sáº½ Ä‘á»c file táº¡i:
# UIT-SE363-Big-Data-Platform-Application-Development/processed_data/text/TRAINING_TEXT_DATA_FINAL_COMBINED.csv
# VÃ¬ váº­y sau khi combine trong preprocess/, hÃ£y copy/sync file COMBINED sang Ä‘Ãºng vá»‹ trÃ­ trÃªn.

# 3. Split data
cd ../UIT-SE363.../train_eval_module
python scripts/split_data.py

# 4. Analyze splits (kiá»ƒm tra)
python scripts/analyze_text_splits.py

# 5. Train models
cd text
python train.py --model_idx 0  # CafeBERT
python train.py --model_idx 1  # XLM-RoBERTa
python train.py --model_idx 2  # DistilBERT

# 6. Test models
python test.py --model_idx 0
python test.py --model_idx 1
python test.py --model_idx 2
```

### B. Checklist khi crawl thÃªm data

- [ ] Äáº£m báº£o video files náº±m trong `harmful/` hoáº·c `not_harmful/` folder
- [ ] Comments file Ä‘áº·t cÃ¹ng folder vá»›i video: `{video_id}_comments.xlsx`
- [ ] Cáº­p nháº­t `DATA_SOURCES` trong `configs/paths.py` náº¿u thÃªm folder má»›i
- [ ] Cháº¡y láº¡i toÃ n bá»™ pipeline tá»« merge Ä‘áº¿n train
- [ ] Verify báº±ng `analyze_text_splits.py` - kiá»ƒm tra khÃ´ng cÃ³ videos bá»‹ drop

### C. Data contract (Ä‘á»ƒ trÃ¡nh lá»—i align/split)

- [ ] `video_id` pháº£i Ä‘á»c/ghi dáº¡ng **string** (trÃ¡nh float scientific notation)
- [ ] CSV pháº£i cÃ³ tá»‘i thiá»ƒu: `video_id`, `text`, `label`, vÃ  (`filename` hoáº·c `path`)
- [ ] Náº¿u file COMBINED lÃ  gá»™p nhiá»u source (data/data_1/data_viet) thÃ¬ má»i bÆ°á»›c â€œcheck tá»“n táº¡i videoâ€ pháº£i xÃ©t Ä‘á»§ cÃ¡c source

---

*End of ETL Report*
