# ğŸ¯ MLFLOW INTEGRATION - FINAL REPORT
## TÃ­ch há»£p MLflow cho Model Registry & Auto-Update

> **NgÃ y táº¡o:** 2025-01-27  
> **Status:** âœ… **SETUP HOÃ€N Táº¤T** - Ready to integrate into training scripts

---

## ğŸ“‹ TÃ“M Táº®T NHANH

### âœ… ÄÃ£ hoÃ n thÃ nh:

1. **MLflow Server** - ThÃªm vÃ o docker-compose.yml âœ…
2. **MLflow Client Utilities** - `streaming/mlflow/client.py` âœ…
3. **Auto-Updater** - `streaming/mlflow/model_updater.py` âœ…
4. **MLflow Logger** - `train_eval_module/shared_utils/mlflow_logger.py` âœ…
5. **Documentation** - `MLFLOW_INTEGRATION_GUIDE.md` (hÆ°á»›ng dáº«n chi tiáº¿t) âœ…
6. **UI/UX Checklist** - `UI_UX_CHECKLIST.md` (liá»‡t kÃª issues cáº§n fix) âœ…

---

## ğŸ—ï¸ KIáº¾N TRÃšC ÄÃƒ XÃ‚Y Dá»°NG

### 1. MLflow Server (Port 5000)

**Location:** `streaming/docker-compose.yml`

**Features:**
- Tracking Server (File-based backend)
- Artifact Store (File system)
- Model Registry (3 models: text, video, fusion)
- Web UI: `http://localhost:5000`

**Storage:**
- Backend: `streaming/state/mlflow_backend/`
- Artifacts: `streaming/state/mlflow_artifacts/`

### 2. MLflow Client (`streaming/mlflow/client.py`)

**Class:** `MLflowModelRegistry`

**Functions:**
- `log_model()` - Log model vÃ o MLflow registry
- `get_latest_model_version()` - Láº¥y version má»›i nháº¥t
- `compare_and_update_model()` - So sÃ¡nh F1 vÃ  quyáº¿t Ä‘á»‹nh update
- `download_model()` - Download model tá»« registry

**Model Registry Names:**
- `text_classification_model`
- `video_classification_model`
- `fusion_multimodal_model`

**F1 Thresholds:**
- Text: 0.75
- Video: 0.70
- Fusion: 0.80

### 3. Auto-Updater (`streaming/mlflow/model_updater.py`)

**Class:** `ModelAutoUpdater`

**Features:**
- Background thread check má»—i 30 phÃºt (configurable)
- Compare F1 score vá»›i model hiá»‡n táº¡i
- Auto-download vÃ  update náº¿u F1 tá»‘t hÆ¡n
- Lazy reload (khÃ´ng cáº§n restart streaming)

**Workflow:**
```
Every 30 minutes:
  â”œâ”€â–º Check MLflow registry
  â”œâ”€â–º Get latest model version
  â”œâ”€â–º Compare F1 scores
  â””â”€â–º If new F1 > current F1 AND new F1 > threshold:
      â”œâ”€â–º Download new model
      â”œâ”€â–º Update model path
      â””â”€â–º Log update event
```

### 4. MLflow Logger (`train_eval_module/shared_utils/mlflow_logger.py`)

**Functions:**
- `log_text_model()` - Wrapper cho text models
- `log_video_model()` - Wrapper cho video models
- `log_fusion_model()` - Wrapper cho fusion models
- `log_model_to_mlflow()` - Generic logger

**Usage:**
```python
from shared_utils.mlflow_logger import log_text_model

# Sau training
log_text_model(
    model_path="path/to/best_checkpoint",
    metrics={"eval_f1": 0.85, "eval_accuracy": 0.90},
    params={"model_name": "xlm-roberta-base", "batch_size": 8},
    model_name="xlm-roberta-base",
)
```

---

## ğŸ”„ WORKFLOW CHI TIáº¾T

### Phase 1: Training â†’ MLflow (Log Models)

```
Training Script (train.py)
    â”‚
    â”œâ”€â–º Train Model
    â”œâ”€â–º Evaluate â†’ Metrics (F1, Accuracy, ...)
    â”œâ”€â–º Save best_checkpoint
    â””â”€â–º mlflow_logger.log_model()
         â”‚
         â”œâ”€â–º Connect MLflow (http://mlflow:5000)
         â”œâ”€â–º Create/Get experiment: "tiktok_safety_{model_type}"
         â”œâ”€â–º Start new run
         â”œâ”€â–º Log metrics: eval_f1, eval_accuracy, ...
         â”œâ”€â–º Log params: batch_size, lr, epochs, ...
         â”œâ”€â–º Upload model artifact (best_checkpoint folder)
         â””â”€â–º Register to Model Registry: "{model_type}_classification_model"
              â””â”€â–º Stage: "None" (default)

Promote to Production (manual hoáº·c auto):
  - F1 > threshold â†’ Promote to "Production"
  - Hoáº·c promote manual qua MLflow UI
```

### Phase 2: Streaming â†’ MLflow (Auto-Update)

```
Streaming Service (spark_processor.py)
    â”‚
    â”œâ”€â–º Start ModelAutoUpdater (background thread)
    â””â”€â–º Every 30 minutes:
         â”œâ”€â–º Check MLflow registry
         â”œâ”€â–º For each model_type (text, video, fusion):
         â”‚   â”œâ”€â–º Get latest version from Production stage
         â”‚   â”œâ”€â–º Get F1 score from run metrics
         â”‚   â”œâ”€â–º Compare with current F1:
         â”‚   â”‚   â”œâ”€â–º If new F1 > current F1 AND new F1 > threshold:
         â”‚   â”‚   â”‚   â”œâ”€â–º Download model tá»« MLflow
         â”‚   â”‚   â”‚   â”œâ”€â–º Save to: /models/{type}/mlflow/{type}_latest
         â”‚   â”‚   â”‚   â”œâ”€â–º Update model_paths[model_type]
         â”‚   â”‚   â”‚   â””â”€â–º Log update event
         â”‚   â”‚   â””â”€â–º Else: Skip update
         â”‚   â””â”€â–º Sleep 30 minutes â†’ Repeat

Model Reload (lazy loading):
  â”œâ”€â–º Models load lazy khi first inference
  â”œâ”€â–º If model_path changed â†’ Next inference load model má»›i
  â””â”€â–º KhÃ´ng cáº§n restart streaming service
```

---

## ğŸ“ Cáº¤U TRÃšC FILES

```
streaming/
â”œâ”€â”€ docker-compose.yml              # [UPDATED] Added MLflow service
â”‚
â”œâ”€â”€ mlflow/                         # [NEW] MLflow utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ client.py                   # MLflowModelRegistry class
â”‚   â””â”€â”€ model_updater.py            # ModelAutoUpdater class
â”‚
â””â”€â”€ state/
    â”œâ”€â”€ mlflow_backend/             # [NEW] MLflow backend (SQLite)
    â””â”€â”€ mlflow_artifacts/           # [NEW] MLflow artifacts (models)

train_eval_module/
â””â”€â”€ shared_utils/
    â””â”€â”€ mlflow_logger.py            # [NEW] Logger cho training scripts

Root/
â”œâ”€â”€ MLFLOW_INTEGRATION_GUIDE.md     # [NEW] HÆ°á»›ng dáº«n chi tiáº¿t
â”œâ”€â”€ MLFLOW_SETUP_COMPLETE.md        # [NEW] Quick start guide
â”œâ”€â”€ MLFLOW_FINAL_REPORT.md          # [NEW] This report
â””â”€â”€ UI_UX_CHECKLIST.md              # [NEW] UI/UX issues list
```

---

## ğŸš€ CÃCH Sá»¬ Dá»¤NG

### 1. Start MLflow Server

```bash
cd /home/guest/Projects/SE363/UIT-SE363-Big-Data-Platform-Application-Development/streaming
conda activate SE363
./start_all.sh
```

MLflow sáº½ tá»± Ä‘á»™ng start vÃ  accessible táº¡i: `http://localhost:5000`

### 2. Log Model sau Training

**Trong training script** (text/video/fusion), thÃªm vÃ o cuá»‘i function:

```python
from shared_utils.mlflow_logger import log_text_model

# Sau trainer.train()
log_text_model(
    model_path=save_path,
    metrics={"eval_f1": 0.85, "eval_accuracy": 0.90},
    params={"model_name": "xlm-roberta-base", "batch_size": 8},
    model_name="xlm-roberta-base",
)
```

**Xem chi tiáº¿t:** `MLFLOW_INTEGRATION_GUIDE.md` section 3

### 3. Enable Auto-Update trong Streaming

**Trong spark_processor.py**, thÃªm vÃ o `main()`:

```python
from mlflow.model_updater import ModelAutoUpdater

model_updater = ModelAutoUpdater(
    tracking_uri=MLFLOW_TRACKING_URI,
    check_interval_minutes=30,
    model_paths={...},
    current_metrics={...},
)
model_updater.start()
```

**Xem chi tiáº¿t:** `MLFLOW_INTEGRATION_GUIDE.md` section 4

### 4. Access MLflow UI

**URL:** `http://localhost:5000`

**Features:**
- Experiments: Xem táº¥t cáº£ training runs
- Models: Xem registered models
- Compare: So sÃ¡nh metrics giá»¯a cÃ¡c runs
- Promote: Promote models to Production

---

## âš™ï¸ CONFIGURATION

### Environment Variables

```bash
# MLflow Configuration
MLFLOW_TRACKING_URI=http://mlflow:5000  # Internal (Docker)
MLFLOW_TRACKING_URI=http://localhost:5000  # External (Development)

# Auto-Update Settings
MLFLOW_ENABLED=true
MLFLOW_UPDATE_INTERVAL_MINUTES=30

# F1 Thresholds
MLFLOW_TEXT_F1_THRESHOLD=0.75
MLFLOW_VIDEO_F1_THRESHOLD=0.70
MLFLOW_FUSION_F1_THRESHOLD=0.80
```

### Model Registry Stages

```
None â†’ Staging â†’ Production

Auto-promote rules:
- F1 > threshold â†’ Promote to "Production"
- Manual promote qua MLflow UI hoáº·c API
```

---

## ğŸ“Š SO SÃNH TRÆ¯á»šC/SAU

### TrÆ°á»›c MLflow:

| Task | Method | Issues |
|------|--------|--------|
| **Model Management** | Hardcoded paths trong code | âŒ KhÃ³ track versions |
| **Model Update** | Manual copy/restart | âŒ Tá»‘n thá»i gian, dá»… sai |
| **Metrics Tracking** | Logs files | âŒ KhÃ³ so sÃ¡nh |
| **Model Registry** | KhÃ´ng cÃ³ | âŒ KhÃ³ quáº£n lÃ½ |

### Sau MLflow:

| Task | Method | Benefits |
|------|--------|----------|
| **Model Management** | MLflow Model Registry | âœ… Version control, stages |
| **Model Update** | Auto-update má»—i 30p | âœ… Tá»± Ä‘á»™ng, khÃ´ng cáº§n restart |
| **Metrics Tracking** | MLflow Tracking | âœ… So sÃ¡nh, charts, search |
| **Model Registry** | MLflow Registry | âœ… Production-ready models |

---

## ğŸ§ª TESTING

### Test 1: MLflow Connection

```bash
# Test tá»« host
curl http://localhost:5000/health

# Test tá»« container
docker exec spark-processor python -c "
from mlflow import set_tracking_uri
set_tracking_uri('http://mlflow:5000')
from mlflow.tracking import MlflowClient
client = MlflowClient()
print('âœ… MLflow connected')
"
```

### Test 2: Log Model

```python
# test_mlflow_log.py
from train_eval_module.shared_utils.mlflow_logger import log_text_model

log_text_model(
    model_path="train_eval_module/text/output/xlm-roberta-base/train/best_checkpoint",
    metrics={"eval_f1": 0.85, "eval_accuracy": 0.90},
    params={"model_name": "xlm-roberta-base"},
    model_name="xlm-roberta-base",
)
```

### Test 3: Auto-Updater

```python
# test_auto_updater.py
from streaming.mlflow.model_updater import ModelAutoUpdater

updater = ModelAutoUpdater(
    check_interval_minutes=1,  # Test vá»›i 1 phÃºt
    current_metrics={"text": 0.80, "video": 0.75, "fusion": 0.85},
)

# Check once
updater.check_and_update_models()
```

---

## âš ï¸ TROUBLESHOOTING

### Issue 1: MLflow connection failed

**Error:** `Connection refused to http://mlflow:5000`

**Solution:**
- Kiá»ƒm tra MLflow container: `docker ps | grep mlflow`
- Kiá»ƒm tra network: `docker network inspect tiktok-network`
- Kiá»ƒm tra env var: `MLFLOW_TRACKING_URI`

### Issue 2: Model not found in registry

**Error:** `No model found in registry for text`

**Solution:**
- Äáº£m báº£o Ä‘Ã£ log model sau training
- Kiá»ƒm tra experiment name match
- Kiá»ƒm tra model registry name match

### Issue 3: F1 score not found

**Error:** `No F1 score found for latest model`

**Solution:**
- Äáº£m báº£o metrics Ä‘Æ°á»£c log vá»›i key "eval_f1" hoáº·c "f1"
- Kiá»ƒm tra run metrics trong MLflow UI

### Issue 4: Model download failed

**Error:** `Failed to download model`

**Solution:**
- Kiá»ƒm tra artifact store path
- Kiá»ƒm tra permissions
- Kiá»ƒm tra disk space

---

## ğŸ“ NEXT STEPS

### 1. â³ Integrate vÃ o Training Scripts

Cáº§n modify cÃ¡c training scripts Ä‘á»ƒ log vÃ o MLflow:

- `train_eval_module/text/train.py` - ThÃªm `log_text_model()` sau training
- `train_eval_module/video/train.py` - ThÃªm `log_video_model()` sau training
- `train_eval_module/fusion/train.py` - ThÃªm `log_fusion_model()` sau training

**Xem hÆ°á»›ng dáº«n:** `MLFLOW_INTEGRATION_GUIDE.md` section 3

### 2. â³ Integrate Auto-Updater vÃ o Streaming

Cáº§n modify `spark_processor.py` Ä‘á»ƒ enable auto-update:

- ThÃªm `ModelAutoUpdater` vÃ o `main()`
- Update `current_metrics` tá»« actual test results
- Handle model path updates

**Xem hÆ°á»›ng dáº«n:** `MLFLOW_INTEGRATION_GUIDE.md` section 4

### 3. â³ Test End-to-End

- Train model â†’ Log vÃ o MLflow â†’ Check registry â†’ Auto-update trong streaming

---

## ğŸ¯ Káº¾T LUáº¬N

### âœ… ÄÃ£ setup hoÃ n táº¥t:

1. âœ… MLflow Server running (port 5000)
2. âœ… MLflow Client utilities ready
3. âœ… Auto-Updater mechanism ready
4. âœ… MLflow Logger ready
5. âœ… Documentation complete

### â³ Cáº§n integrate tiáº¿p:

1. â³ Modify training scripts Ä‘á»ƒ log vÃ o MLflow
2. â³ Integrate auto-updater vÃ o spark_processor.py
3. â³ Test end-to-end workflow

### ğŸ“š Documentation:

- **`MLFLOW_INTEGRATION_GUIDE.md`** - HÆ°á»›ng dáº«n chi tiáº¿t tá»«ng bÆ°á»›c
- **`MLFLOW_SETUP_COMPLETE.md`** - Quick start guide
- **`UI_UX_CHECKLIST.md`** - UI/UX issues list

---

## ğŸ”— LINKS

- **MLflow UI:** http://localhost:5000
- **MLflow Docs:** https://mlflow.org/docs/latest/index.html
- **Integration Guide:** `MLFLOW_INTEGRATION_GUIDE.md`

---

**MLflow integration setup Ä‘Ã£ hoÃ n táº¥t! Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u integrate vÃ o training scripts theo hÆ°á»›ng dáº«n trong `MLFLOW_INTEGRATION_GUIDE.md`.**
