# üìä B√ÅO C√ÅO PH√ÇN T√çCH H·ªÜ TH·ªêNG
## Multimodal Real-Time Detection of Harmful TikTok Content

> **Ng√†y t·∫°o:** 2025-01-27  
> **Phi√™n b·∫£n:** 1.0  
> **M·ª•c ƒë√≠ch:** Ph√¢n t√≠ch chi ti·∫øt c·∫•u tr√∫c h·ªá th·ªëng, c√°c ƒë∆∞·ªùng d·∫´n config, models v√† streaming pipeline

---

## üìã M·ª§C L·ª§C

1. [Danh s√°ch ƒë∆∞·ªùng d·∫´n t·ª´ c√°c file config](#1-danh-s√°ch-ƒë∆∞·ªùng-d·∫´n-t·ª´-c√°c-file-config)
2. [Ph√¢n t√≠ch chi ti·∫øt train_eval_module](#2-ph√¢n-t√≠ch-chi-ti·∫øt-train_eval_module)
3. [Ph√¢n t√≠ch chi ti·∫øt streaming pipeline](#3-ph√¢n-t√≠ch-chi-ti·∫øt-streaming-pipeline)

---

## 1. DANH S√ÅCH ƒê∆Ø·ªúNG D·∫™N T·ª™ C√ÅC FILE CONFIG

### 1.1. Train Eval Module Configs

#### üìÅ `train_eval_module/configs/paths.py`

**ƒê∆∞·ªùng d·∫´n Base:**
```
CURRENT_DIR = train_eval_module/
BASE_PROJECT_PATH = .. (root project)/
```

**ƒê∆∞·ªùng d·∫´n Data Sources (Raw):**
- `DATA_SOURCES = ["data", "data_1", "data_viet"]`
- Video directories t·ª± ƒë·ªông qu√©t:
  - `{BASE_PROJECT_PATH}/data/videos/harmful/`
  - `{BASE_PROJECT_PATH}/data/videos/not_harmful/`
  - `{BASE_PROJECT_PATH}/data_1/videos/harmful/`
  - `{BASE_PROJECT_PATH}/data_1/videos/not_harmful/`
  - `{BASE_PROJECT_PATH}/data_viet/videos/harmful/`
  - `{BASE_PROJECT_PATH}/data_viet/videos/not_harmful/`

**ƒê∆∞·ªùng d·∫´n Text Data:**
- `TEXT_LABEL_FILE = {BASE_PROJECT_PATH}/processed_data/text/TRAINING_TEXT_DATA_FINAL_COMBINED.csv`
- `TEXT_TRAIN_CSV = {BASE_PROJECT_PATH}/processed_data/text/train_split.csv`
- `TEXT_VAL_CSV = {BASE_PROJECT_PATH}/processed_data/text/eval_split.csv`
- `TEXT_TEST_CSV = {BASE_PROJECT_PATH}/processed_data/text/test_split.csv`

**ƒê∆∞·ªùng d·∫´n Video Splits (Master Index):**
- `MASTER_TRAIN_INDEX = train_eval_module/data_splits/train_split.json`
- `MASTER_VAL_INDEX = train_eval_module/data_splits/val_split.json`
- `MASTER_TEST_INDEX = train_eval_module/data_splits/test_split.json`

**ƒê∆∞·ªùng d·∫´n Fusion Data:**
- `FUSION_TRAIN_JSON = {BASE_PROJECT_PATH}/processed_data/fusion/train_fusion.json`
- `FUSION_VAL_JSON = {BASE_PROJECT_PATH}/processed_data/fusion/val_fusion.json`
- `FUSION_TEST_JSON = {BASE_PROJECT_PATH}/processed_data/fusion/test_fusion.json`

**ƒê∆∞·ªùng d·∫´n Output/Logs:**
- `OUTPUT_DIR = train_eval_module/output/`
- `LOG_DIR = train_eval_module/logs/`
- `PROCESSED_DIR = {BASE_PROJECT_PATH}/processed_data/`
- `AUDIO_DATA_DIR = {BASE_PROJECT_PATH}/processed_data/audios/`

#### üìÅ `train_eval_module/text/text_configs.py`

**Model Paths:**
- Text model checkpoints:
  - `train_eval_module/text/output/uitnlp_CafeBERT/train/best_checkpoint/`
  - `train_eval_module/text/output/xlm-roberta-base/train/best_checkpoint/`
  - `train_eval_module/text/output/distilbert-base-multilingual-cased/train/best_checkpoint/`

**Log Paths:**
- `train_eval_module/text/logs/{model_name}/test_results_{model_name}.json`

#### üìÅ `train_eval_module/video/video_configs.py`

**Model Configs:**
- VideoMAE: `MCG-NJU/videomae-base-finetuned-kinetics`
- TimeSformer: `facebook/timesformer-base-finetuned-k400`
- ViViT: `google/vivit-b-16x2-kinetics400`

**Output Paths:**
- `train_eval_module/video/output/MCG-NJU_videomae-base-finetuned-kinetics/train/best_checkpoint/`

#### üìÅ `train_eval_module/fusion/fusion_configs.py`

**Model Paths (Fusion Input):**
- `text_model_path = train_eval_module/text/output/xlm-roberta-base/train/best_checkpoint`
- `video_model_path = train_eval_module/video/output/MCG-NJU_videomae-base-finetuned-kinetics/train/best_checkpoint`

**Fusion Output:**
- `train_eval_module/fusion/output/fusion_videomae/checkpoint-{epoch}/`

#### üìÅ `train_eval_module/audio/audio_configs.py`

**Audio Models:**
- `microsoft/wavlm-base`
- `microsoft/wavlm-base-plus`
- `facebook/wav2vec2-base`

**Audio Output:**
- `train_eval_module/audio/output/`
- `train_eval_module/audio/audio_model/checkpoint-{epoch}/`

### 1.2. Streaming Module Configs

#### üìÅ `streaming/ingestion/config.py`

**Container Paths (Docker):**
- `BASE_DIR = /opt/project/streaming/ingestion`
- `STREAMING_DIR = /opt/project/streaming`
- `DATA_DIR = /opt/project/streaming/data`

**Local Paths (Development):**
- `DATA_DIR = streaming/data/`
- `CRAWL_DIR = streaming/data/crawl/`
- `VIDEO_DIR = streaming/data/videos/`
- `AUDIO_DIR = streaming/data/audios/`
- `TEMP_DOWNLOAD_DIR = streaming/ingestion/temp_downloads/`

**File Paths:**
- `INPUT_CSV_PATH = streaming/data/crawl/tiktok_links_viet.csv`
- `COOKIES_PATH = streaming/ingestion/cookies.txt`

**Service Endpoints:**
- `MINIO_ENDPOINT = minio:9000` (internal) / `localhost:9000` (external)
- `KAFKA_BOOTSTRAP_SERVERS = ["kafka:29092"]` (internal) / `["localhost:9092"]` (external)
- `KAFKA_TOPIC = "tiktok_raw_data"`
- `MINIO_BUCKET = "tiktok-raw-videos"`
- `MINIO_AUDIO_BUCKET = "tiktok-raw-audios"`

#### üìÅ `streaming/processing/spark_processor.py`

**Model Paths (Mounted in Docker):**
- `PATH_TEXT_MODEL = /models/text/output/uitnlp_CafeBERT/train/best_checkpoint_FocalLoss`
- `PATH_VIDEO_MODEL = /models/video/output/MCG-NJU_videomae-base-finetuned-kinetics/train/best_checkpoint`
- `PATH_AUDIO_MODEL = /models/audio/audio_model/checkpoint-2300`

**Local Mapping:**
- Docker volume mount: `../train_eval_module:/models`
- Spark checkpoint: `/opt/spark/checkpoints/tiktok_multimodal` ‚Üí `streaming/state/spark_checkpoints/`

**Database:**
- `POSTGRES_HOST = postgres` (container) / `localhost` (external)
- `POSTGRES_PORT = 5432`
- `POSTGRES_DB = tiktok_safety_db`
- `POSTGRES_USER = user`
- `POSTGRES_PASSWORD = password`

#### üìÅ `streaming/docker-compose.yml`

**Volume Mounts:**
- `./processing:/app/processing` ‚Üí Spark code
- `./ingestion:/app/ingestion` ‚Üí Ingestion code
- `../train_eval_module:/models` ‚Üí AI models
- `./state/minio_data:/data` ‚Üí MinIO storage
- `./state/postgres_data:/var/lib/postgresql/data` ‚Üí Postgres data
- `./state/airflow_logs:/opt/airflow/logs` ‚Üí Airflow logs
- `./state/spark_checkpoints:/opt/spark/checkpoints` ‚Üí Spark checkpoints
- `./state/ivy2:/tmp/.ivy2` ‚Üí Spark dependencies cache
- `./state/chrome_profile:/workspace/chrome_profile` ‚Üí Chrome profile
- `./airflow/dags:/opt/airflow/dags` ‚Üí Airflow DAGs
- `./dashboard:/app` ‚Üí Dashboard code

**Service Ports:**
- Zookeeper: `2181`
- Kafka: `9092` (external), `29092` (internal)
- MinIO: `9000` (API), `9001` (Console)
- Postgres: `5432`
- Spark Master: `9090` (UI), `7077` (RPC)
- Airflow: `8080` (Webserver)
- Dashboard: `8501`

#### üìÅ `streaming/airflow/dags/`

**DAG Paths:**
- `1_TIKTOK_ETL_COLLECTOR.py` ‚Üí DAG ID: `1_TIKTOK_ETL_COLLECTOR`
- `2_TIKTOK_STREAMING_PIPELINE.py` ‚Üí DAG ID: `2_TIKTOK_STREAMING_PIPELINE`

**Task Paths (Container):**
- `INGESTION_PATH = /opt/project/streaming/ingestion`
- `DATA_DIR = /opt/project/streaming/data`

#### üìÅ `streaming/infra/postgres/init.sql`

**Database Schema:**
- Table: `processed_results`
- Table: `system_logs`

---

## 2. PH√ÇN T√çCH CHI TI·∫æT TRAIN_EVAL_MODULE

### 2.1. T·ªïng quan c·∫•u tr√∫c

```
train_eval_module/
‚îú‚îÄ‚îÄ text/              # Text classification models
‚îú‚îÄ‚îÄ video/             # Video classification models
‚îú‚îÄ‚îÄ audio/             # Audio classification models
‚îú‚îÄ‚îÄ fusion/            # Multimodal fusion models
‚îú‚îÄ‚îÄ configs/           # Shared configuration (paths)
‚îú‚îÄ‚îÄ data_splits/       # Train/val/test JSON splits
‚îú‚îÄ‚îÄ output/            # Model checkpoints
‚îî‚îÄ‚îÄ logs/              # Training logs
```

### 2.2. TEXT MODELS

#### 2.2.1. Models ƒë∆∞·ª£c s·ª≠ d·ª•ng

**1. CafeBERT (`uitnlp/CafeBERT`)**
- **M·ª•c ƒë√≠ch:** T·ªëi ∆∞u cho ti·∫øng Vi·ªát
- **Ki·∫øn tr√∫c:** BERT-based (Vietnamese)
- **Tham s·ªë:** ~110M
- **Config:**
  - `max_text_len: 512`
  - `batch_size: 8`
  - `grad_accum: 8` (effective batch = 64)
  - `lr: 1.5e-5`
  - `epochs: 10`

**2. XLM-RoBERTa (`xlm-roberta-base`)**
- **M·ª•c ƒë√≠ch:** T·ªët cho d·ªØ li·ªáu ƒëa ng√¥n ng·ªØ (Anh/Vi·ªát/H√†n...)
- **Ki·∫øn tr√∫c:** RoBERTa-based (Multilingual)
- **Tham s·ªë:** ~270M
- **Config:**
  - `max_text_len: 512`
  - `batch_size: 8`
  - `grad_accum: 8`
  - `lr: 1.5e-5`
  - `epochs: 10`

**3. DistilBERT (`distilbert-base-multilingual-cased`)**
- **M·ª•c ƒë√≠ch:** Nh·∫π, nhanh, ƒëa ng√¥n ng·ªØ
- **Ki·∫øn tr√∫c:** Distilled BERT (Multilingual)
- **Tham s·ªë:** ~134M
- **Config:**
  - `max_text_len: 512`
  - `batch_size: 32`
  - `grad_accum: 2` (effective batch = 64)
  - `lr: 3e-5`
  - `epochs: 15`

#### 2.2.2. Ph∆∞∆°ng ph√°p x·ª≠ l√Ω Text

**Input Processing:**
1. **Text Aggregation:** G·ªôp nhi·ªÅu comments th√†nh 1 string
   - Format: `comment1 [SEP] comment2 [SEP] ...`
   - Max length: 512 tokens (t·ª± ƒë·ªông truncate b·ªüi tokenizer)

2. **Tokenization:**
   - D√πng AutoTokenizer t·ª´ HuggingFace
   - Padding/truncation t·ª± ƒë·ªông
   - Special tokens: `[CLS]`, `[SEP]`, `[PAD]`

3. **Model Architecture:**
   - **Backbone:** Pretrained encoder (BERT/RoBERTa)
   - **Head:** Classification head (2 classes: safe/harmful)
   - **Dropout:** 0.1 (hidden_dropout_prob, attention_probs_dropout_prob)
   - **Output:** Logits ‚Üí Softmax ‚Üí Probability

**Training Strategy:**
- **Loss Function:** CrossEntropyLoss v·ªõi class weights
- **Class Weights:** `[0.5808, 3.5942]` (harmful boost ~6x) - x·ª≠ l√Ω class imbalance
- **Optimizer:** AdamW
- **Scheduler:** Cosine annealing v·ªõi warmup (15% epochs)
- **Regularization:**
  - Weight decay: 0.1
  - Max grad norm: 1.0
  - Label smoothing: 0.05
- **Early Stopping:** Patience = 3 epochs
- **Metric:** Eval F1 (weighted F1) l√†m best model selection

**Model Loading (inference):**
```python
# File: text/src/model.py
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
# Forward: [CLS] token embedding ‚Üí classifier ‚Üí logits
```

### 2.3. VIDEO MODELS

#### 2.3.1. Models ƒë∆∞·ª£c s·ª≠ d·ª•ng

**1. VideoMAE (`MCG-NJU/videomae-base-finetuned-kinetics`)**
- **M·ª•c ƒë√≠ch:** Model ch√≠nh ƒë∆∞·ª£c s·ª≠ d·ª•ng (balance t·ªët gi·ªØa accuracy v√† speed)
- **Ki·∫øn tr√∫c:** Video Masked Autoencoder (Vision Transformer)
- **Tham s·ªë:** ~87M
- **Processor:** VideoMAEImageProcessor
- **Config:**
  - `num_frames: 16`
  - `image_size: 224`
  - `batch_size: 4`
  - `grad_accum: 16` (effective batch = 64)
  - `lr: 3e-5`

**2. TimeSformer (`facebook/timesformer-base-finetuned-k400`)**
- **Ki·∫øn tr√∫c:** Space-Time Attention
- **Tham s·ªë:** ~121M
- **Processor:** AutoImageProcessor

**3. ViViT (`google/vivit-b-16x2-kinetics400`)**
- **Ki·∫øn tr√∫c:** Video Vision Transformer
- **Tham s·ªë:** ~300M+
- **Processor:** VivitImageProcessor

#### 2.3.2. Ph∆∞∆°ng ph√°p x·ª≠ l√Ω Video

**Frame Extraction:**
1. **Decord VideoReader:** ƒê·ªçc video MP4
2. **Frame Sampling:** Uniform sampling 16 frames
   - C√¥ng th·ª©c: `indices = np.linspace(0, len(video)-1, 16).astype(int)`
   - 16 frames ƒë∆∞·ª£c ch·ªçn ƒë·ªÅu nhau t·ª´ video

**Preprocessing:**
1. **VideoMAE Processor:**
   - Resize frames ‚Üí 224x224
   - Normalize pixel values
   - Format: `(Batch, Channels, Time, Height, Width)` = `(B, 3, 16, 224, 224)`

2. **Model Input:**
   - VideoMAE: Patch embedding ‚Üí Transformer encoder ‚Üí Classification token
   - Output shape: `(B, 768)` feature vector

**Model Architecture:**
```python
# File: video/src/model.py
processor = VideoMAEImageProcessor.from_pretrained(model_name)
model = VideoMAEForVideoClassification.from_pretrained(
    model_name,
    num_labels=2,  # safe/harmful
    hidden_dropout_prob=0.1,
    attention_probs_dropout_prob=0.1
)
```

**Training Strategy:**
- **Loss:** CrossEntropyLoss
- **Optimizer:** AdamW (lr=3e-5, weight_decay=0.01)
- **Scheduler:** Cosine v·ªõi warmup 10%
- **Metric:** Eval F1
- **Checkpointing:** Best model theo eval_f1

### 2.4. AUDIO MODELS

#### 2.4.1. Models ƒë∆∞·ª£c s·ª≠ d·ª•ng

**1. WavLM (`microsoft/wavlm-base`)**
- **Ki·∫øn tr√∫c:** Self-supervised speech model
- **Tham s·ªë:** ~95M

**2. WavLM Plus (`microsoft/wavlm-base-plus`)**
- **Tham s·ªë:** ~95M+ (enhanced)

**3. Wav2Vec2 (`facebook/wav2vec2-base`)**
- **Ki·∫øn tr√∫c:** Self-supervised audio model
- **Tham s·ªë:** ~95M

#### 2.4.2. Ph∆∞∆°ng ph√°p x·ª≠ l√Ω Audio

**Audio Preprocessing:**
1. **Extraction:** FFmpeg extract audio t·ª´ video MP4 ‚Üí WAV
2. **Sampling Rate:** 16kHz
3. **Max Duration:** 10 seconds (truncate/pad)
4. **Feature Extraction:**
   - AutoFeatureExtractor t·ª´ HuggingFace
   - Raw audio waveform ‚Üí Spectrogram features

**Config:**
- `sampling_rate: 16000`
- `max_duration_sec: 10.0`
- `batch_size: 4`
- `grad_accum: 8` (effective batch = 32)
- **Dropout OFF:** T·∫•t c·∫£ dropout = 0.0 (gi·∫£i quy·∫øt underfitting)

**Training Strategy:**
- **Loss:** CrossEntropyLoss
- **Metric:** Accuracy (kh√¥ng d√πng F1 do data imbalance √≠t h∆°n)
- **Warmup:** 10%
- **Early Stopping:** Patience = 5

### 2.5. FUSION MODEL

#### 2.5.1. Ki·∫øn tr√∫c Late Fusion

**M√¥ h√¨nh:**
```
Text Backbone (XLM-RoBERTa) ‚Üí Text Features (768-dim)
Video Backbone (VideoMAE)    ‚Üí Video Features (768-dim)
                                  ‚Üì
                         Fusion Layer
                                  ‚Üì
                        Classifier (2 classes)
```

#### 2.5.2. Chi·∫øn l∆∞·ª£c Fusion

**1. Concat Fusion (Simple):**
```python
combined = concat(text_feat * text_weight, video_feat * video_weight)
# Output: (B, 1536) ‚Üí Classifier ‚Üí (B, 2)
```
- **Weights:** `text_weight=0.5`, `video_weight=0.5`
- **Fusion hidden:** 256
- **Classifier:** Linear(1536 ‚Üí 256 ‚Üí 2)

**2. Attention Fusion (Advanced):**
```python
# Cross-Modal Attention
text_attended = CrossAttention(text_proj, video_proj)  # Text attends to Video
video_attended = CrossAttention(video_proj, text_proj) # Video attends to Text
# Gating mechanism
gate = Sigmoid(Linear(concat(text_attended, video_attended)))
combined = gate * text_attended + (1 - gate) * video_attended
```
- **Attention heads:** 4
- **Fusion hidden:** 256
- **Gating:** Adaptive weighting gi·ªØa text v√† video

#### 2.5.3. Fine-tuning Strategy

**Unfreeze Strategy:**
- **Text backbone:** Unfreeze last 2 layers (default: full freeze)
- **Video backbone:** Unfreeze last 2 layers (default: full freeze)
- **Classifier:** Always trainable

**Training Config:**
- `batch_size: 8`
- `grad_accum: 4` (effective batch = 32)
- `lr: 2e-5`
- `weight_decay: 0.05`
- `epochs: 10`
- `fusion_hidden: 256`
- `stop_patience: 5`

**Input Processing:**
- **Text:** 1 string ƒë√£ concat (kh√¥ng c·∫ßn CommentAggregator)
- **Video:** 16 frames, 224x224
- **Labels:** Binary (0=safe, 1=harmful)

**Model Implementation:**
```python
# File: fusion/src/model.py
class LateFusionModel(nn.Module):
    - text_backbone: AutoModel (frozen, last 2 layers unfrozen)
    - video_backbone: AutoModel (frozen, last 2 layers unfrozen)
    - fusion_layer: Concat or Attention
    - classifier: Sequential(Linear, BatchNorm, ReLU, Dropout, Linear)
```

---

## 3. PH√ÇN T√çCH CHI TI·∫æT STREAMING PIPELINE

### 3.1. T·ªïng quan Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     AIRFLOW ORCHESTRATION                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  DAG 1: ETL COLLECTOR                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇ Check DB     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Crawl Links  ‚îÇ                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ                                   ‚îÇ                          ‚îÇ
‚îÇ                                   ‚ñº                          ‚îÇ
‚îÇ                         CSV: tiktok_links_viet.csv          ‚îÇ
‚îÇ                                                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  DAG 2: STREAMING PIPELINE (Self-loop)                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇPrepare  ‚îÇ‚îÄ‚ñ∂‚îÇCheck Infra‚îÇ‚îÄ‚ñ∂‚îÇIngestion    ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                     ‚îÇ                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇLoop     ‚îÇ‚óÄ‚îÄ‚îÇWait 30s  ‚îÇ‚óÄ‚îÄ‚îÇVerify Spark‚îÇ                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA FLOW PIPELINE                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  [1] INGESTION LAYER                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇDownload    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇExtract Audio‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇUpload MinIO‚îÇ        ‚îÇ
‚îÇ  ‚îÇ(yt-dlp)    ‚îÇ    ‚îÇ(ffmpeg)     ‚îÇ    ‚îÇ(S3 API)    ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                               ‚îÇ              ‚îÇ
‚îÇ                                               ‚ñº              ‚îÇ
‚îÇ  [2] KAFKA LAYER                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ Topic: tiktok_raw_data                     ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ Message: {video_id, minio_path, text, ...}‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                 ‚îÇ                                            ‚îÇ
‚îÇ                 ‚ñº                                            ‚îÇ
‚îÇ  [3] SPARK LAYER                                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ Spark Streaming Processor                        ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îÇText Model‚îÇ  ‚îÇVideo Model‚îÇ  ‚îÇAudio Model‚îÇ      ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ(CafeBERT)‚îÇ  ‚îÇ(VideoMAE)‚îÇ  ‚îÇ(WavLM)    ‚îÇ      ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ       ‚îÇ              ‚îÇ              ‚îÇ             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ       ‚ñº              ‚ñº              ‚ñº             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  text_score    video_score    audio_score        ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ       ‚îÇ              ‚îÇ              ‚îÇ             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ                              ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                    ‚ñº                              ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ          avg_score = TEXT*0.3 + VIDEO*0.7        ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ          final_decision = (avg >= 0.5) ? harmful ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                       ‚îÇ                                      ‚îÇ
‚îÇ                       ‚ñº                                      ‚îÇ
‚îÇ  [4] DATABASE LAYER                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ Postgres: processed_results (UPSERT)     ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                 ‚îÇ                                           ‚îÇ
‚îÇ                 ‚ñº                                           ‚îÇ
‚îÇ  [5] DASHBOARD LAYER                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ Streamlit: Real-time visualization       ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ - Metrics, confusion matrix, time series        ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2. CHI TI·∫æT T·ª™NG LAYER

#### 3.2.1. INGESTION LAYER

**V·ªã tr√≠:** `streaming/ingestion/`

**Components:**
1. **Crawler (`crawler.py`):**
   - Selenium + Chrome headless (Xvfb)
   - Crawl TikTok links t·ª´ hashtags
   - Output: CSV `tiktok_links_viet.csv`
   - Risky hashtags filter (blacklist keywords)

2. **Downloader (`downloader.py`):**
   - yt-dlp wrapper ƒë·ªÉ download video
   - Retry logic v·ªõi backoff
   - Extract video ID t·ª´ URL
   - Extract comments t·ª´ TikTok API

3. **Audio Processor (`audio_processor.py`):**
   - FFmpeg extract audio t·ª´ video MP4 ‚Üí WAV
   - 16kHz sampling rate
   - Max duration 10s

4. **Main Worker (`main_worker.py`):**
   - Orchestrate: Download ‚Üí Audio ‚Üí MinIO ‚Üí Kafka
   - ThreadPoolExecutor (max_workers=2) ƒë·ªÉ parallel processing
   - Cleanup temp files sau upload

5. **Clients:**
   - **MinioClient (`clients/minio_kafka_clients.py`):**
     - Upload video: `raw/{label}/{video_id}.mp4`
     - Upload audio: `raw/{label}/{video_id}.wav`
     - Buckets: `tiktok-raw-videos`, `tiktok-raw-audios`
   - **KafkaClient (`clients/minio_kafka_clients.py`):**
     - Producer g·ª≠i message JSON:
       ```json
       {
         "video_id": "...",
         "minio_video_path": "bucket/object",
         "minio_audio_path": "bucket/object",
         "clean_text": "...",
         "csv_label": "harmful|safe",
         "timestamp": 1234567890.0
       }
       ```
   - **Data Cleaner (`clients/data_cleaner.py`):**
     - Text normalization
     - Remove emoji, special chars
     - Lowercase conversion

**Workflow:**
```
CSV Input ‚Üí Download Video ‚Üí Extract Audio ‚Üí Upload MinIO ‚Üí Send Kafka
```

**ƒê∆∞·ªùng d·∫´n quan tr·ªçng:**
- Input: `streaming/data/crawl/tiktok_links_viet.csv`
- Temp: `streaming/ingestion/temp_downloads/`
- MinIO: `s3://tiktok-raw-videos/raw/{label}/{video_id}.mp4`
- Kafka: Topic `tiktok_raw_data`

#### 3.2.2. SPARK LAYER

**V·ªã tr√≠:** `streaming/processing/spark_processor.py`

**Ki·∫øn tr√∫c Spark Streaming:**
- **Format:** Kafka Stream (Structured Streaming)
- **Checkpoint:** `streaming/state/spark_checkpoints/tiktok_multimodal`
- **Starting Offsets:** `latest` (m·∫∑c ƒë·ªãnh) ho·∫∑c `earliest`
- **Max Offsets Per Trigger:** 5 messages/batch

**Models Loading (Lazy):**
- **Text Model:** CafeBERT (`/models/text/output/uitnlp_CafeBERT/train/best_checkpoint_FocalLoss`)
- **Video Model:** VideoMAE (`/models/video/output/MCG-NJU_videomae-base-finetuned-kinetics/train/best_checkpoint`)
- **Audio Model:** WavLM (`/models/audio/audio_model/checkpoint-2300`) - placeholder

**Processing Logic:**

**1. Text Processing (UDF):**
```python
def process_text_logic(text):
    # Rule-based: Check blacklist keywords
    if any(kw in text.lower() for kw in BLACKLIST_KEYWORDS):
        return {"risk_score": 0.85, "verdict": "harmful"}
    # AI Model: CafeBERT inference
    inputs = tokenizer(text, ...)
    outputs = model(**inputs)
    probs = softmax(outputs.logits)
    return {"risk_score": probs[0][1], "verdict": "harmful" if probs[0][1] > 0.5 else "safe"}
```

**2. Video Processing (UDF):**
```python
def process_video_logic(video_id, minio_path):
    # Download t·ª´ MinIO ‚Üí temp file
    s3.download_file(...)
    # Extract 16 frames (uniform sampling)
    vr = VideoReader(temp_file)
    indices = np.linspace(0, len(vr)-1, 16).astype(int)
    frames = vr.get_batch(indices)
    # VideoMAE inference
    inputs = processor(frames, ...)
    outputs = model(**inputs)
    probs = softmax(outputs.logits)
    return {"risk_score": probs[0][1], "verdict": "harmful" if probs[0][1] > 0.5 else "safe"}
```

**3. Score Aggregation:**
```python
# Weighted average
text_weight = 0.3  # ENV: TEXT_WEIGHT
video_weight = 0.7  # = 1.0 - text_weight
avg_score = text_score * text_weight + video_score * video_weight
final_decision = "harmful" if avg_score >= threshold else "safe"
# threshold = 0.5 (ENV: DECISION_THRESHOLD)
```

**4. Database Write (UPSERT):**
```sql
INSERT INTO processed_results (...) VALUES (...)
ON CONFLICT (video_id) DO UPDATE SET
    text_verdict = EXCLUDED.text_verdict,
    video_verdict = EXCLUDED.video_verdict,
    avg_score = EXCLUDED.avg_score,
    final_decision = EXCLUDED.final_decision,
    processed_at = CURRENT_TIMESTAMP
```

**T·ªëi ∆∞u h√≥a:**
- **Lazy Model Loading:** Ch·ªâ load model khi c·∫ßn (singleton pattern)
- **Persist:** `StorageLevel.MEMORY_AND_DISK` ƒë·ªÉ cache UDF results
- **Batch Processing:** Micro-batches (5 messages/trigger)
- **De-dup:** Remove duplicate video_id trong c√πng batch tr∆∞·ªõc khi UPSERT

#### 3.2.3. DATABASE LAYER

**V·ªã tr√≠:** `streaming/infra/postgres/init.sql`

**Schema:**

**Table `processed_results`:**
```sql
CREATE TABLE processed_results (
    video_id VARCHAR(50) PRIMARY KEY,
    raw_text TEXT,
    human_label VARCHAR(20),
    text_verdict VARCHAR(20),
    text_score FLOAT,
    video_verdict VARCHAR(20),
    video_score FLOAT,
    avg_score FLOAT,
    threshold FLOAT,
    final_decision VARCHAR(50),
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Table `system_logs`:**
```sql
CREATE TABLE system_logs (
    id SERIAL PRIMARY KEY,
    dag_id VARCHAR(50),
    task_name VARCHAR(50),
    log_level VARCHAR(10),
    message TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

**Indexes:** (n√™n th√™m ƒë·ªÉ t·ªëi ∆∞u queries)
- `processed_at` (time-series queries)
- `final_decision` (filtering)

#### 3.2.4. AIRFLOW LAYER

**V·ªã tr√≠:** `streaming/airflow/dags/`

**DAG 1: `1_TIKTOK_ETL_COLLECTOR`**
- **Schedule:** None (manual trigger) ho·∫∑c `0 */6 * * *` (6h interval)
- **Tasks:**
  1. `monitor_db_health`: Check Postgres connection
  2. `crawl_tiktok_links`: Run crawler (Xvfb mode, timeout 45min)
- **Output:** CSV `tiktok_links_viet.csv`

**DAG 2: `2_TIKTOK_STREAMING_PIPELINE`**
- **Schedule:** None (self-loop trigger)
- **Tasks:**
  1. `prepare_environment`: Check CSV file exists
  2. `check_kafka_infra`: Check Kafka connectivity
  3. `run_ingestion_worker`: Run ingestion (timeout 30min)
  4. `verify_spark_ai_result`: SqlSensor check processed_results (poke mode, 20s interval, 300s timeout)
  5. `wait_30s_cooldown`: Cooldown ƒë·ªÉ gi·∫£i ph√≥ng t√†i nguy√™n
  6. `loop_self_trigger`: Trigger l·∫°i ch√≠nh n√≥ (self-loop)
- **Concurrency:** `max_active_runs=1` (ch·ªâ 1 instance t·∫°i 1 th·ªùi ƒëi·ªÉm)

**Executor:** LocalExecutor (cho ph√©p parallel tasks trong c√πng DAG)

**Logs:** `streaming/state/airflow_logs/`

#### 3.2.5. DASHBOARD LAYER

**V·ªã tr√≠:** `streaming/dashboard/`

**Tech Stack:**
- Streamlit
- Plotly (charts)
- Pandas (data processing)
- SQLAlchemy (database queries)

**Features:**
- Real-time metrics (accuracy, precision, recall, F1)
- Confusion matrix
- Time series charts (processed_at)
- Video preview (MinIO public URL)

**Config:**
- Postgres connection t·ª´ env vars
- MinIO public endpoint t·ª´ env vars

### 3.3. DOCKER DEPLOYMENT STRUCTURE

#### 3.3.1. Docker Compose Services

**Infrastructure Services:**
1. **Zookeeper:**
   - Image: `confluentinc/cp-zookeeper:7.4.0`
   - Port: 2181
   - Purpose: Kafka coordination

2. **Kafka:**
   - Image: `confluentinc/cp-kafka:7.4.0`
   - Ports: 9092 (external), 29092 (internal)
   - Health check: `kafka-topics --list`
   - Purpose: Message queue

3. **MinIO:**
   - Image: `minio/minio`
   - Ports: 9000 (API), 9001 (Console)
   - Volumes: `./state/minio_data:/data`
   - Buckets: `tiktok-raw-videos`, `tiktok-raw-audios`
   - Init job: `minio-init` container t·∫°o buckets

4. **Postgres:**
   - Image: `postgres:15`
   - Port: 5432
   - Volumes: `./state/postgres_data:/var/lib/postgresql/data`
   - Init scripts: `./infra/postgres/init.sql`

**Processing Services:**
5. **Spark Master:**
   - Build: `./spark/Dockerfile`
   - Ports: 9090 (UI), 7077 (RPC)
   - Volumes: Models, processing code

6. **Spark Worker:**
   - Build: `./spark/Dockerfile`
   - Memory: 12g worker, 10g executor
   - Volumes: Models, processing code

7. **Spark Processor:**
   - Build: `./spark/Dockerfile`
   - Auto-start: Spark streaming job
   - Volumes: Checkpoints, ivy2 cache
   - Env vars: TEXT_WEIGHT, DECISION_THRESHOLD, KAFKA_STARTING_OFFSETS

**Orchestration Services:**
8. **Airflow DB:**
   - Image: `postgres:13`
   - Purpose: Airflow metadata

9. **Airflow Init:**
   - Build: `./airflow/Dockerfile.airflow`
   - One-shot: Initialize DB + create admin user

10. **Airflow Webserver:**
    - Build: `./airflow/Dockerfile.airflow`
    - Port: 8080
    - Volumes: DAGs, logs, ingestion code

11. **Airflow Scheduler:**
    - Build: `./airflow/Dockerfile.airflow`
    - Shm: 2gb (cho Chrome)
    - Volumes: DAGs, logs, chrome_profile

**UI Services:**
12. **Dashboard:**
    - Build: `./dashboard/Dockerfile.dashboard`
    - Port: 8501
    - Volumes: Dashboard code

13. **DB Migrator:**
    - Image: `postgres:15`
    - One-shot: Create `system_logs` table

#### 3.3.2. Dockerfile Optimizations

**Spark Dockerfile (`streaming/spark/Dockerfile`):**
```dockerfile
# LAYER 1: System deps (rarely changes)
RUN apt-get install ffmpeg libsndfile1 ...

# LAYER 2: Python constraints (rarely changes)
RUN pip install "typing-extensions<4.6.0" "zipp<3.16.0"

# LAYER 3: PyTorch CPU-only (LARGE, stable)
RUN pip install torch==2.1.2 --index-url https://download.pytorch.org/whl/cpu

# LAYER 4: AI/ML libs (medium, stable)
RUN pip install transformers==4.30.2 decord av ...

# LAYER 5: Utils (small, may change)
COPY requirements.txt /tmp/requirements.txt
RUN pip install -r /tmp/requirements.txt

# LAYER 6: Permissions (always last)
RUN mkdir -p /tmp/.ivy /opt/spark/work /app/processing && chmod 777 ...

# LAYER 7: Application code (changes frequently - LAST)
COPY spark_processor.py /app/processing/
```

**T·ªëi ∆∞u:** Layers t·ª´ stable ‚Üí volatile ƒë·ªÉ t·∫≠n d·ª•ng Docker cache

**Airflow Dockerfile (`streaming/airflow/Dockerfile.airflow`):**
- System: Chrome + XVFB
- Python deps: Selenium, webdriver-manager
- Copy DAGs v√† scripts

**Dashboard Dockerfile (`streaming/dashboard/Dockerfile.dashboard`):**
- Base: Python 3.10-slim
- Install: libpq-dev (Postgres client)
- Copy requirements ‚Üí pip install
- Copy source code

#### 3.3.3. Volume Mounts

**Persistent Volumes (state/):**
- `./state/minio_data` ‚Üí MinIO storage (~GB)
- `./state/postgres_data` ‚Üí Postgres data (~MB)
- `./state/airflow_logs` ‚Üí Airflow execution logs (~MB)
- `./state/spark_checkpoints` ‚Üí Spark streaming state (~MB)
- `./state/ivy2` ‚Üí Spark dependencies cache (~MB)
- `./state/chrome_profile` ‚Üí Chrome cookies/session (~MB)

**Code Volumes:**
- `./processing` ‚Üí `/app/processing` (Spark)
- `./ingestion` ‚Üí `/app/ingestion` (Airflow tasks)
- `../train_eval_module` ‚Üí `/models` (AI models)
- `./airflow/dags` ‚Üí `/opt/airflow/dags` (Airflow DAGs)
- `./dashboard` ‚Üí `/app` (Dashboard)

**Network:**
- Name: `tiktok-network` (bridge driver)
- All services trong c√πng network ‚Üí d√πng service name ƒë·ªÉ communicate

### 3.4. CONFIGURATIONS & ENVIRONMENT VARIABLES

#### 3.4.1. Environment Variables (.env)

```bash
# AI Model Weights
TEXT_WEIGHT=0.3          # Default 0.3 (30% text, 70% video)
DECISION_THRESHOLD=0.5   # Default 0.5

# Kafka
KAFKA_STARTING_OFFSETS=latest  # latest ho·∫∑c earliest

# Spark Checkpoint
SPARK_CHECKPOINT_DIR=/opt/spark/checkpoints/tiktok_multimodal

# Postgres
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=tiktok_safety_db
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# MinIO
MINIO_ENDPOINT=http://minio:9000
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=password123
MINIO_BUCKET_VIDEOS=tiktok-raw-videos
MINIO_BUCKET_AUDIOS=tiktok-raw-audios
MINIO_PUBLIC_ENDPOINT=http://localhost:9000  # External access

# Airflow
AIRFLOW_DB_USER=airflow
AIRFLOW_DB_PASSWORD=airflow
AIRFLOW_DB_NAME=airflow
AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_WEBSERVER_SECRET_KEY=my_very_secret_key_123
```

#### 3.4.2. Spark Configurations

**Spark Session:**
```python
SparkSession.builder
    .config("spark.sql.streaming.checkpointLocation", SPARK_CHECKPOINT_DIR)
    .config("spark.executor.memory", "8g")
    .config("spark.python.worker.memory", "2g")
    .config("spark.network.timeout", "600s")
```

**Kafka Consumer:**
```python
spark.readStream.format("kafka")
    .option("kafka.bootstrap.servers", "kafka:29092")
    .option("subscribe", "tiktok_raw_data")
    .option("startingOffsets", "latest")
    .option("maxOffsetsPerTrigger", 5)
```

### 3.5. T·ªêI ∆ØU H√ìA & BEST PRACTICES

#### 3.5.1. ƒê√£ t·ªëi ∆∞u

‚úÖ **Docker Layer Caching:**
- Stable layers (system deps, PyTorch) tr∆∞·ªõc
- Volatile layers (source code) cu·ªëi
- Gi·∫£m build time khi code thay ƒë·ªïi

‚úÖ **Lazy Model Loading:**
- Models ch·ªâ load khi c·∫ßn (singleton pattern)
- Gi·∫£m memory footprint khi idle

‚úÖ **Batch Processing:**
- Micro-batches (5 messages/trigger) ƒë·ªÉ balance latency v√† throughput
- Persist UDF results ƒë·ªÉ tr√°nh recompute

‚úÖ **UPSERT Strategy:**
- ON CONFLICT DO UPDATE ƒë·ªÉ handle duplicates
- De-dup trong batch tr∆∞·ªõc khi write

‚úÖ **Checkpointing:**
- Spark checkpoint ƒë·ªÉ resume sau restart
- Kafka offsets ƒë∆∞·ª£c track t·ª± ƒë·ªông

‚úÖ **Health Checks:**
- T·∫•t c·∫£ services c√≥ health checks
- Depends_on v·ªõi conditions (service_healthy, service_completed_successfully)

#### 3.5.2. C√≥ th·ªÉ c·∫£i thi·ªán

‚ö†Ô∏è **Database Indexes:**
- Thi·∫øu indexes cho `processed_at`, `final_decision` ‚Üí queries ch·∫≠m h∆°n

‚ö†Ô∏è **Model Caching:**
- Models load m·ªói Spark worker ‚Üí memory overhead
- C√≥ th·ªÉ d√πng Spark broadcast variables

‚ö†Ô∏è **Error Handling:**
- UDF exceptions ƒë∆∞·ª£c catch nh∆∞ng kh√¥ng retry
- C√≥ th·ªÉ implement exponential backoff

‚ö†Ô∏è **Monitoring:**
- Thi·∫øu metrics (Prometheus/Grafana)
- Logging ch∆∞a structured (JSON format)

‚ö†Ô∏è **Scaling:**
- Spark worker c·ªë ƒë·ªãnh (1 worker)
- C√≥ th·ªÉ scale horizontal b·∫±ng docker-compose scale

---

## üìå T·ªîNG K·∫æT

### Train Eval Module:
- **Text:** 3 models (CafeBERT, XLM-RoBERTa, DistilBERT) v·ªõi class weights 6x boost
- **Video:** VideoMAE (16 frames, 224x224)
- **Audio:** WavLM (16kHz, 10s max)
- **Fusion:** Late fusion v·ªõi attention mechanism

### Streaming Pipeline:
- **5 Layers:** Ingestion ‚Üí Kafka ‚Üí Spark ‚Üí Database ‚Üí Dashboard
- **13+ Docker Services:** Zookeeper, Kafka, MinIO, Postgres, Spark (Master/Worker/Processor), Airflow (DB/Init/Webserver/Scheduler), Dashboard, DB Migrator
- **Orchestration:** Airflow DAGs v·ªõi self-loop
- **Models:** CafeBERT (text), VideoMAE (video), WavLM (audio - placeholder)

### ƒê∆∞·ªùng d·∫´n quan tr·ªçng:
- **Models:** `train_eval_module/output/{model_name}/train/best_checkpoint/`
- **Data:** `streaming/data/crawl/tiktok_links_viet.csv`
- **Storage:** MinIO buckets `tiktok-raw-videos`, `tiktok-raw-audios`
- **Database:** Postgres `tiktok_safety_db.processed_results`
- **Checkpoints:** `streaming/state/spark_checkpoints/`

---

**T√†i li·ªáu n√†y cung c·∫•p c√°i nh√¨n t·ªïng quan chi ti·∫øt v·ªÅ to√†n b·ªô h·ªá th·ªëng. C√≥ th·ªÉ d√πng l√†m t√†i li·ªáu tham kh·∫£o cho development v√† maintenance.**
